{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydub\n",
    "# !pip install ipywidgets\n",
    "# !apt-get install -y ffmpeg\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.getcwd().split('/')[-1] == 'notebooks'\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display, Markdown, Audio\n",
    "import requests\n",
    "import torch\n",
    "import numpy as np\n",
    "import io\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io.wavfile import read, write\n",
    "import warnings\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import tempfile\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [30, 15]\n",
    "from ipywidgets import HBox, Label, VBox\n",
    "from ipywidgets import widgets\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store paths in aux variables\n",
    "fastp0 = '../output/FastPitch_checkpoint_100.pt'\n",
    "fastp1500 = '../output/FastPitch_checkpoint_1500.pt'\n",
    "fastp3000 = '../output/FastPitch_checkpoint_3000.pt'\n",
    "waveg = '../pretrained_models/waveglow/nvidia_waveglow256pyt_fp16.pt'\n",
    "flags0 = f'--cuda --fastpitch {fastp0} --waveglow {waveg} --wn-channels 256'\n",
    "flags1500 = f'--cuda --fastpitch {fastp1500} --waveglow {waveg} --wn-channels 256'\n",
    "flags3000 = f'--cuda --fastpitch {fastp3000} --waveglow {waveg} --wn-channels 256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://tts.test.vocacloud.net/tts/generate\"\n",
    "\n",
    "def get_temp_filename(mydir=\".\",prefix=\"temp_\", suffix=\"\"):\n",
    "    \n",
    "    \"\"\" return a string in the form of temp_X, where X is a large integer \"\"\"\n",
    "    file = tempfile.mkstemp(suffix=suffix, prefix=prefix, dir=mydir) \n",
    "    os.close(file[0])\n",
    "    return file[1] \n",
    "\n",
    "def generate_kwargs_for_voca(text,what):\n",
    "    headers = {'Authorization': 'Bearer a2f4cd32-f5f6-46fa-952a-b27697382b10',\n",
    "               'Content-Type': 'application/json; version=1'}\n",
    "    kwargs = {}\n",
    "    kwargs['headers'] = headers\n",
    "    json_data = {\"sentence\": text, \"volume\": 1, \"speed\": 1, \"sampleRate\": 22050, \"reply_fields\": what,\"exclude_preprocess\": [\"speech_acronyms\",\n",
    "            \"gen_abbr\",\n",
    "            \"sms_abbr\",\n",
    "            \"chat_abbr\",\n",
    "            \"year_date\",\n",
    "            \"month_date\",\n",
    "            \"weekday_date\",\n",
    "            \"gen_date\",\n",
    "            \"cardinal_num\",\n",
    "            \"decimal_num\",\n",
    "            \"symbols\",\n",
    "            \"time\",\n",
    "            \"oov_pronounce\",\n",
    "            \"units_abbr\"] }\n",
    "    return json_data, kwargs\n",
    "\n",
    "def getDetailsFromTTS(text,what,url):\n",
    "    sentence = text\n",
    "    json_data, kwargs = generate_kwargs_for_voca(sentence, what)\n",
    "    rawResponse = requests.post(url, json=json_data, stream=True, verify=False, **kwargs)\n",
    "    reply = torch.load(io.BytesIO(rawResponse.content))\n",
    "    return reply\n",
    "\n",
    "def get_current_jenny(input):\n",
    "    with open(input,\"r\") as f:\n",
    "        text = f.readline()\n",
    "    rep = getDetailsFromTTS(text,['mel', 'align_logist', 'frame_length', 'sample_rate',\"signal\",\"align_text\"],url)\n",
    "    return rep[\"signal\"].numpy(),int(rep[\"sample_rate\"]),rep[\"mel\"].numpy(),rep[\"align_logist\"].numpy(),rep[\"align_text\"].numpy()\n",
    "    \n",
    "\n",
    "text = \"hi there\"\n",
    "what = ['mel', 'align_logist', 'frame_length', 'sample_rate',\"signal\",\"align_text\"]\n",
    "# json_data, kwargs = generate_kwargs_for_voca(text, what)\n",
    "# rawResponse = requests.post(url, json=json_data, stream=True, verify=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = {}\n",
    "with open(\"../Jenny/metadata.csv\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    s = line.split(\"|\")\n",
    "    sentences[s[1]] = s[0]\n",
    "    \n",
    "# for s in sentences.keys():\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../pitch_transform.py\n",
    "# import torch\n",
    "\n",
    "# def pitch_transform_custom(pitch, duration):\n",
    "# # pitch = pitch + 110\n",
    "# #     print(\"---!\")\n",
    "# #     #duration = duration * 0 + 1.5\n",
    "# #     #pitch = pitch * 0 + 300\n",
    "# #     print(duration)\n",
    "# #     print(pitch)\n",
    "# #     #pitch_offset = [0, -11.734620465350275, -28.689850792933385, 0, -44.61186523887815, -45.70688894982871, 0, -56.560140114505515, -52.77171128844202, -58.20461132565032, -105.01983787614819, -124.48284897082337, -116.23204895517284, -116.23204895517284, 0, 0, -64.71739562158871, 0, -38.5914461297364, -42.897411924509385, 0, 0, -3.3426176814817268, -12.247741709341824, 5.828423138490507, 0, 0, 0, 0, 0, 0, 295.5051434349008, 0, -13.84992685544674, -8.756527112814183, -11.744156656968755, -11.744156656968755, 0, -16.215855559479365, -43.01594103179767, 0, 0, 0, 0, 0, -10.952073349230062, -16.445555763011413, -16.445555763011413, -16.445555763011413, -16.445555763011413, -22.59699129071464, -22.59699129071464, -26.005503905906323, 0, -30.1506943181019, -30.1506943181019, -33.673773790807786, 0, -33.591902348573, 33.02369931724701, 16.906020670352575, 16.906020670352575, 0, 0, 0, -18.83333666886324, -25.158673490755348, -35.46426430051292, -35.46426430051292, 0, 294.5591855863818, 0, 0, -83.69600586493456, -22.06781578151788, 0, 0   ]\n",
    "# #     #pitch = pitch + torch.tensor(pitch_offset).to(\"cuda\")\n",
    "# #     print(\"---!\")\n",
    "# #     pitch[0][-6] = 180  \n",
    "# #     pitch[0][-5] = 260  \n",
    "# #     pitch[0][-4] = 360  \n",
    "# #     pitch[0][-3] = 360  \n",
    "# #     pitch[0][-2] = 380  \n",
    "# #     pitch[0][-1] = 400  \n",
    "# #     duration = duration*1.3\n",
    "\n",
    "#     return pitch ,duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def match_target_amplitude(myFile, target_dBFS):\n",
    "    sound = AudioSegment.from_file(myFile, \"wav\")\n",
    "    change_in_dBFS = target_dBFS - sound.dBFS\n",
    "    sound = sound.apply_gain(change_in_dBFS)\n",
    "    sound.export(myFile, format=\"wav\")\n",
    "    \n",
    "!mkdir -p Q\n",
    "\n",
    "def generate_samples(text,index):\n",
    "    train_id = sentences[text]\n",
    "\n",
    "    file = get_temp_filename(\"/tmp\",\"temp_\",\".txt\")\n",
    "    with open(file,\"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "    # JENNY PART\n",
    "    wav_name = \"../Jenny/wavs/{}.wav\".format(train_id)\n",
    "    !cp {wav_name} Q/a_{index}.wav\n",
    "    match_target_amplitude(f\"Q/a_{index}.wav\", -20.0)\n",
    "    \n",
    "    # TACOTRON PART\n",
    "    out,sr,mel,align, align_text = get_current_jenny(file)\n",
    "    api_file = get_temp_filename(\"/tmp\",\"temp_\",\".wav\")\n",
    "    write(f\"Q/b_{index}.wav\", 22050, out)\n",
    "    match_target_amplitude(f\"Q/b_{index}.wav\", -20.0)\n",
    "\n",
    "    # FASTPITCH PART\n",
    "    !python ../inference.py {flags3000} -i {file} -o output/out --pitch-transform-custom  --speaker 0 --n-speakers 2 >/dev/null\n",
    "\n",
    "    melFile = 'output/out/audio_0_mel.pt'\n",
    "    reply_fields=['signal','sample_rate','mel_before_denoiser','mel_after_denoiser']\n",
    "    with open(melFile, 'rb') as fin:\n",
    "        vocoder_url = \"http://tts.test.vocacloud.net/tts/mel2wav\" \n",
    "        files = {'file': fin,'reply_fields': json.dumps(reply_fields)}\n",
    "        rawResponse = requests.post(vocoder_url, files=files, stream=True,verify=False)\n",
    "    try:\n",
    "        reply = torch.load(io.BytesIO(rawResponse.content))\n",
    "    except Exception as ex:\n",
    "        print(rawResponse.content)\n",
    "\n",
    "    write(f\"Q/c_{index}.wav\", reply[\"sample_rate\"], reply[\"signal\"].numpy())\n",
    "    match_target_amplitude(f\"Q/c_{index}.wav\", -20.0)\n",
    "\n",
    "\n",
    "random.seed(3)\n",
    "sentences2 = list(sentences.keys())\n",
    "random.shuffle(sentences2)\n",
    "for i,s in enumerate(sentences2[0:30]):\n",
    "    print(i)\n",
    "    generate_samples(s,i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
